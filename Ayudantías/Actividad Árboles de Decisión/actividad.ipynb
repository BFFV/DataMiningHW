{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 3. _Decision Trees_\n",
    "<hr/>\n",
    "\n",
    "**Profesor:** \n",
    "- Mauricio Arriagada \n",
    "\n",
    "**Ayudantes:**\n",
    "- Felipe Barrientos (fnbarrientos@uc.cl)\n",
    "- Javier Dreves (jidreves@uc.cl)\n",
    "- Joaquin Eichholz (jeichholz3@uc.cl)\n",
    "- Astrid San Martín (aesanmar@uc.cl)\n",
    "\n",
    "\n",
    "**Antes de comenzar:**\n",
    "\n",
    "- Laboratorio debe ser realizado **de forma individual**. Obviamente, se pueden discutir ideas, pero cualquier intercambio de códigos **no está permitido**.\n",
    "- Recuerda orientar tu programación a un paradigma funcional.\n",
    "- **¡ Comenta todo tu código !**\n",
    "\n",
    "**Instrucciones de entrega:**\n",
    "\n",
    "- Debe entregar este laboratorio por `siding`, en sección `cuestionarios`. Descargar archivo \".ipynb\" a su equipo y luego subirlo. (También pueden trabajarlo en colab)\n",
    "- Plazo máximo de entrega: **Martes 1 de Octubre, 10.59 pm.**\n",
    "\n",
    "**Evaluación:**\n",
    "- La estructura del código = 0.5\n",
    "- Salida exitosa = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actividad Decission Tree\n",
    "\n",
    "En esta actividad deberan implementar desde cero el algoritmo decission Tree y clasificar la base de datos de la encuesta Cases2017 para clasificar la variable ytotcorh (Ingreso total del hogar corregido), luego deben evaluar la efectividad de su algoritmo con precision y recall. \n",
    "\n",
    "Se espera que propongan una o más soluciones para mejorar la efectividad de su algoritmo, pueden realizar una poda del arbol para evitar overfing y/o definir una regla de cuando detener las divisiones en un nodo \n",
    "\n",
    "\n",
    "\n",
    "#### Resumen Decission Tree\n",
    "    \n",
    "    1.- Todos los registros son iguales? \n",
    "        si -> nodo hoja \n",
    "        no -> contiuar en (2)\n",
    "    2.- Tomar la feature que mejor separe los registros de la base de datos\n",
    "    3.- Usar el atributo como nodo raiz\n",
    "    4.- Dividir el set de entrenamiento segun este atributo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos a programar `:)`\n",
    "\n",
    "\n",
    "**Construcción de cada nodo del arbol**\n",
    "\n",
    "   - Lo primero que vamos a hacer es generar cada nodo del árbol (que a su vez es la raíz de otro arbol). Es importante recordar que esta estructura de datos será recursiva. \n",
    "   - Cada nodo (sub-árbol) tendrá asociado una base de datos, una categoría, un valor, su padre y un array correspondientes a sus hijos (que son clase Node). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    \n",
    "    def __init__(self, df, value=None, father=None, category=None):\n",
    "        slf.df = df\n",
    "        self.category = category\n",
    "        self.value = value\n",
    "        self.father = father\n",
    "        self.children = np.array()                \n",
    "          \n",
    "          \n",
    "    def append_children(self):\n",
    "        \"\"\" \n",
    "        Agregar un nuevo hijo al arbol nodo \n",
    "        \"\"\"\n",
    "        return None \n",
    "    \n",
    "    \n",
    "    def select_feature(self):\n",
    "        \"\"\"\n",
    "        Este metodo calcula la entropia de la base de datos y retorna la feature que\n",
    "        mejor separa los registos de las distintas clases\n",
    "        \"\"\"        \n",
    "        return \n",
    "       \n",
    "    \n",
    "    def split_data_base(self, feature):\n",
    "        \"\"\"\n",
    "        Este metodo recibe una feature y divide la base de datos en base a ella \n",
    "        generando los hijos del nodo.\n",
    "        \"\"\"\n",
    "        return None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Construcción de cada nodo del arbol**\n",
    "\n",
    "   - Primero hay que crear una función que fitee el arbol dados los datos. \n",
    "   - Predict tiene que darnos una predicción de la feature buscada dados los valores de las otras features.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(dataset, min_data, max_deep):\n",
    "    \"\"\"\n",
    "    Crear recursivamente el arbol con los datos. El algoritmo debe parar cuando se llega a una altura máxima\n",
    "    o cuando queda un mínimo de datos en el set de datos de cada nodo. \n",
    "    \n",
    "    Debe retonar el primer nodo del árbol completado\n",
    "    \"\"\"\n",
    "    return None \n",
    "\n",
    "\n",
    "def predict(tree, data_to_predict):\n",
    "    \"\"\"\n",
    "    Predice el valor de un dato nuevo (data_to_predict)\n",
    "    \"\"\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "<center> <h1>Fin del laboratorio.</h1> </center>\n",
    "​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
